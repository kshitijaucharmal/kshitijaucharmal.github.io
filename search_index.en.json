[{"url":"https://kshitijaucharmal.github.io/blog/","title":"Blogs","description":null,"body":"\n\t\n\n\n\nWelcome to my blog page. I post about random things, maybe about things I’m learning, tutorials etc\nDo Check these out !!\n","path":null},{"url":"https://kshitijaucharmal.github.io/blog/scenewithcamera/","title":"Flying Around in 3D","description":null,"body":"Repo Link\nSummary\nLet me just show you the progress, then we can talk about what I did:\n\n\n\n  \n        Flying through the world\n    \n\nCool right? Let walk through what improvements have been made since the dawn of the age of triangles.\nSo I managed to get multiple triangles rendering last time, along with colors for vertices.\nI had to remove the vertex colors, as it leads to very bad texture mapping later on, so that means removing the\nEBO (Element Buffer Object) Entirely as well. Its only really useful in cases where you don’t want the object to have\ntextures, or at least if the object can have procedural textures, which I haven’t gotten to yet\nTextures\nI can send the texture coordinates along with vertex data, so that it maps as I want it to.\nThere are modes to how the texture repeats, given as follows:\nOpenGL OptionDescription\nGL_REPEATThe default behavior for textures. Repeats the texture image.\nGL_MIRRORED_REPEATSame as GL_REPEAT but mirrors the image with each repeat.\nGL_CLAMP_TO_EDGEClamps the coordinates between 0 and 1. The result is that higher coordinates become clamped to the edge, resulting in a stretched edge pattern.\nGL_CLAMP_TO_BORDERCoordinates outside the range are now given a user-specified border color.\n\nI just used GL_MIRRORED_REPEAT Mode ’cause the tutorial uses that\nOpenGL also generated Mipmaps on its own using the glGenerateMipmap(GL_TEXTURE_2D) function\nCoordinate Systems\nAnyone who knows the LearnOpenGL website will know I skipped over the transformations section.\nNothing to say about it except installing the glm library, knew how vectors and matrices worked already.\nThis image proves very helpful in understanding the stages of transformations to show a 3D scene on a 2D screen:\n\nEach have been explained in ample detail on the website, so you can check out what each\nstep does. For an overview,\nSpaceDescription\nLocal spaceLocal space is the coordinate space that is local to your object\nWorld spacespace in which the objects can be defined to have a location in 3D space\nView spaceCamera space, space scene from camera’s POV\nClip spaceRange of coordinates that will be displayed, if outside this, they will be removed\nScreen spacePerspective or Othographic, take your pick\n\nThese can be represented / implemented using transformation matrices, and each transformation is applied seperately in order to form a 3D scene\nFootnotes and Next Steps\nAt the end, I implemented the Camera and gave some input instructions to make it a flythrough style camera.\nAlso tidied up the code, not exactly how I want it to be but will refactor it later\nNow, the next steps are not gonna be following the tutorial, as it goes in detail about lighting and stuff,\nwhich is not totally essential right now. The things I need to implement are as follows:\n\nModular system that allows for dynamic creation of objects through UI\nFullscreen/Bigger window editor with imgui windows\nImplementing imguizmo and add gizmos to move/rotate/scale\nImplementing pybind11 to allow creation of objects through python\n\nI wanna try the lighting stuff too, but this comes first. After this is done, I’ll try to implement a physics engine, maybe\nfrom scratch maybe taking a library, and then after the engine is pretty modular and scalable, I’ll try to implement a Ray Tracer in\nit as well.\nSo Stay tuned Guys !!!\nRepo Link\n","path":null},{"url":"https://kshitijaucharmal.github.io/blog/opengl-getting-started/","title":"OpenGL is Awesome!!","description":null,"body":"Okay, so this is gonna be a bit long, get excited!\nLets divide this into three Parts:\n\nOpenGL\nC++\nKdevelop\n\nLets start with OpenGL first.\nOpenGL\n\nOpenGL (Open Graphics Library) is a cross-language, cross-platform application programming\ninterface (API) for rendering 2D and 3D vector graphics\n\nOpenGL is cross-platform like vulkan, and wayyyy easier to understand and code than vulkan.\nWhile vulkan took me one week to get started and to draw a triangle on the screen (the one thing you do first as a\ngraphics programming beginner), OpenGL allowed this to happen in under a few hours !!!\nI’ve identified some differences, which maybe good or bad according to industry standards, but I’ll list them here according to my standards\nLets focus on the good points first:\n\nOpenGL is easy: The code is easy to understand, it does not require a hell lot of setup to get started, and also makes everything easier to understand. I of course am comparing it to Vulkan\nHandles a lot of things on its own: using glad, which is library for managing function pointers for OpenGL, initialization is a cinch\nFast on my machine: Vulkan gave me some lagging when resizing windows, maybe it was my fault (probably), but in OpenGL I just used a callback function and it worked without any significant lags\n\nUnfortunately, OpenGL is not all good:\n\nNot explicit: Many things are handled internally, unlike vulkan which allows for in depth customization of each system using structs.\nNot Shader friendly: Although people may call it shader friendly as you can compile the shaders anywhere you want in the code, but the\ncode has to be compiled and shaders are a part of this. shaders can be kept different from the full code compilation, unlike vulkan.\nSlower: I haven’t personally experienced this, but people have said that Vulkan is much more performant than OpenGL\n\nGiven everything above, I’m going to stick to OpenGL and try my best to make the engine\nNext step will be to integrate Imgui, which is much easier as compared to Vulkan\nCurrent Progress\n\nYup, two triangles forming a rectangle with only 4 vertices defined and 6 indices for drawing/filling in the triangles using VBO and EBO\nThis is the progress I got, and I can even send these values to the vertex shader !!!\nThe process is for rendering anything on the screen is as follows, taken from the LearnOpenGL website\n\nThe Vertex Buffer Objects (VBO) and Element Buffer Objects (EBO) are stored as follows under the Vertex Array Objects\n\nC++\nI’m learning c++ from the c++ playlist series by the cherno, and its been amazing. I understand a lot of concepts, and\nit really allows my code to flow seamlessly. I have taken the liberty to seperate all of the code into seperate files,\ncreating namespaces for certain systems such as WindowManagement and InputManagement.\nThe heirarchy of the code is as follows:\n\nAs you can see, the structure is a pretty standard one with all\nthe headers in the include directory, c++ files in the src directory,\nand the libaries in the external directory. The shaders is for storing the shader files, which is\ncurrently not being used as the shaders are written as const char * (I’m following the tutorial man)\nThe CmakeLists.txt handles everything, and I have a new Target in it to run the program once its compiled as well\nKdevelop\nYeah, I started using Kdevelop. Neovim is amazing, but the syntax highlighting and lsp server messes up as the structure changes.\nIt does not take the CmakeLists.txt in consideration, and hence I’m always faced with not resolved/found errors.\nAs to why I don’t use VSCode, its electron based, and feels too slow for me.\nKdevelop has been perfect, it automatically detects what my CmakeLists.txt defines, and adds targets to the project window.\nIt also has much better autocomplete, vi mode, and my preffered theme ayu-dark built-in, so thats definately a plus.\nI’ve added a custom target to the make system, so that I can just build (the build system is amazing as well, you can just add and remove targets)\nand it will run the binary generated as well. I can’t use harpoon (a nvim plugin) in it, but I’ll soon get used to Kdevelop’s version of it,\nand it definately feels fast as nvim too.\nThats it! That was the update, will see you guys in the next one!!\n","path":null},{"url":"https://kshitijaucharmal.github.io/blog/27-apr-sun/","title":"Switching from Vulkan to OpenGL","description":null,"body":"Its been a while since I started work on the ConceptForge Project, and have no progress to show other than I managed to integrate imgui into vulkan.\nI tried to learn shaders from the Book Of Shaders, and have a basic understanding of how they work, but the problem I’m facing is seperating out the\ncode into multiple files. I’m not very good at cpp, and I shot myself in my foot by taking up this enormous project at the start.\nThe imgui integration:\n\nSo I’ve decided this: Switching from Vulkan to OpenGL. This decision is based on the experience of many graphics programmers who are at a\nmuch higher level than me. I’ll do everything in OpenGL, and once I get the gist of how it works, will maybe come back to Vulkan\nSo Lets go step by step:\nFirstly, learning cpp by following this playlist\nSecondly, Learning OpenGL, will be much easier than Vulkan.\nThen, I’ll integrate imgui in it, which’ll be a cinch too.\nThen, learning shaders and doing some cool stuff using only shaders and the basic engine I’ll have by then\nThe next part will be adding pybind11 and so on.\n\nI’m not giving up, this is still progress !!\n\n","path":null},{"url":"https://kshitijaucharmal.github.io/blog/simengine-06-apr-sun/","title":"Drawing a Triangle (Finally)","description":null,"body":"\n“Yup, all I can show after 2 weeks is this triangle.”\n— Me, after losing sleep to a graphics API\n\n\n\nIf you’ve ever written a graphics engine — or even touched a graphics API — you know that getting a triangle on screen is no joke.\nBut after 2 weeks of wrestling Vulkan into submission, I finally did it.\nAnd this triangle? It’s beautiful.\nNot because it’s a work of art, but because it represents the first real pixel in my AI-powered simulation engine: ConceptForge.\n\nThe Vulkan Struggle Is Real\nI followed the Khronos Vulkan Tutorial to get started.\nOkay fine — partially followed. I may have… copy-pasted a few things without fully understanding them. 🙈 But hey — when you’re dealing with hundreds of lines of boilerplate just to clear the screen, you do what you gotta do.\nVulkan is not like OpenGL. It doesn’t hold your hand.\nIt doesn’t even look at you. It just gives you raw power, and expects you to wire up everything — memory management, pipelines, synchronization, shaders, framebuffers, render passes… all of it.\nBut it does so explicitly, and that’s kind of the genius of it.\n\nStructs, Not Functions\nMost things in Vulkan are set up by creating structs, filling them out, and passing them into Vulkan functions.\nFor example, creating a framebuffer looks like this:\n\nNotice how there’s:\n\nA clearly defined struct with named fields,\nAn explicit sType to describe the structure’s role,\nAnd then a Vulkan function that consumes the whole config.\n\nI actually like this model. It avoids long, confusing function calls with 10+ parameters, and makes the code pretty readable — especially once you understand what the structs do.\n\nIt’s Just a Triangle… or Is It?\nSure, visually it’s just three vertices forming a triangle.\nBut behind the scenes?\n\nVulkan instance setup ✔️\nDevice selection ✔️\nLogical device + queues ✔️\nSwapchain management ✔️\nRender pass &amp; framebuffer setup ✔️\nShaders + pipeline layout ✔️\nCommand buffers &amp; synchronization ✔️\n\nIf that sounds like overkill for a triangle… that’s because it is.\nBut it’s also the groundwork for everything that will follow.\n\nThe Next Step\nNow that I’ve got a triangle on screen, I need a break from Vulkan boilerplate.\nSo, I’m going to integrate Dear ImGui next — to add a nice GUI overlay and make debugging and interaction a lot easier moving forward.\nBeing able to click buttons, inspect data, and tweak values in real-time is going to be a game changer as I start building out the actual engine systems.\n\nThis isn’t just about rendering a triangle.\nIt’s about building the foundation for ConceptForge — my AI-powered simulation engine where users will eventually just describe a world in plain English… and watch it unfold.\nToday, it’s a triangle.\nTomorrow, it’ll be a procedurally generated city full of AI agents reacting to gravity and laser beams.\nStay tuned 🚀\n","path":null},{"url":"https://kshitijaucharmal.github.io/blog/simengine-05-apr-sat/","title":"Concept Forge","description":null,"body":"ConceptForge: Building My AI-Powered Simulation Engine from Scratch\n\n“Describe your world in English. Let the AI bring it to life.”\n\n\nWhat I’m Building\nOver the next six months, I’m working on ConceptForge — an AI-powered simulation engine built completely from scratch, using Vulkan, C++, and a layer of natural language processing magic.\nThis isn’t just a simulation engine. It’s the start of something more — maybe even a game engine down the line. Here’s the dream:\n\nA low-level, high-performance rendering and simulation engine in C++, powered by Vulkan.\nPhysics, real-time simulation, ray tracing (yes, built myself — no Vulkan RTX extensions).\nA Python API using pybind11, so users can write high-level logic easily.\nLLM integration — users can describe scenes in plain English, and the AI will generate Python code behind the scenes.\nGUI using GLFW and ImGui to provide visual feedback, simulation controls, and editing tools.\n\nAll of this is open-source and evolving here:\nGitHub: ConceptForge\n\nHigh-Level Architecture\nThis is the general structure I’m working with:\n\nIt’s a full-stack creative pipeline — except instead of websites, it makes interactive 3D simulations based on natural language prompts.\n\nTech Stack\nTechPurpose\nC++Core simulation logic, ECS, physics, and rendering backend\nVulkanRaw rendering control — full GPU access, custom pipelines, ray tracing\nGLFWWindow/context management\nImGuiEditor UI, debug controls, interactive tweaks\npybind11Binding layer to expose C++ functionality to Python\nPythonUser scripting interface (and what the AI generates)\nLLMsConverts English into code using GPT or custom small models\n\n\nVulkan in Simple Terms\nWhy Vulkan? Because I want total control over how things render, move, and interact — right down to how memory is allocated on the GPU.\nThink of Vulkan like this:\n\nOpenGL holds your hand. Vulkan tells you to build the chair you’re gonna sit on.\nThat means more boilerplate, but also massive control and zero hidden costs.\nPerfect for things like: custom ray tracing, compute shaders, massive simulations, and crazy GPU tricks.\n\n\nThe Vision\nHere’s the core loop I’m building toward:\n\nUser: “Spawn a red sphere on a green plane. Drop a blue cube from 5 meters with gravity.”\n\n\nThe LLM parses this text and generates corresponding Python code using the engine’s API.\nPython runs → pybind11 passes it to the C++ backend.\nSimulation is updated, rendered using Vulkan, displayed in the GLFW window.\nUser can interact, tweak parameters, or add more prompts.\n\nThis bridges natural language + code + simulation, and gives users an almost magical interface to create with.\n\nWhat You’ll Be Able To Do\nEventually, this will support things like:\n\nPrototyping with AI assistance\nSimulating complex systems: physics, particles, ray tracing, ray marching, etc.\nProcedural scene generation via LLMs\nAI agents interacting in a simulated world\nRealtime interactive visualization for data or experiments\n\n\nVisual Overview\nHere’s a high-level diagram of how it all connects:\n\n\nWhy I’m Doing This\nI’ve always wanted an engine where I could just describe what I want, and it would spring to life.\nWe’re at a point now where LLMs are good enough to bridge that gap — but most engines are built from the top-down,\nand not designed for this kind of integration.\nSo I’m doing it differently: bottom-up, from GPU code to English-language scripting, with a clean and extensible architecture in mind.\nThis is going to take time, but I’m documenting every step, and you can follow the journey (and maybe even contribute) on GitHub.\nThe real reason can just be cause I want to :P\n\nFollow the Project\n\nGitHub: ConceptForge\n\nBlog posts, demos, and releases will be linked here as they come out.\n\nGot ideas? Want to contribute? Drop me a message or a GitHub issue.\nLet’s build something wild. 🔥\n","path":null},{"url":"https://kshitijaucharmal.github.io/blog/smartpositioning/","title":"Smart Label Positioning","description":null,"body":"Motivation\nI wanted to take part in #Hacktoberfest this time, and had found this issue.\nThe issue was that the labels overlap, making them harder to read and understand when close together.\n\nPull request\nI created Pull Request\nwith the changes, showcasing the changes as follows:\n\n\n\n Label Annotator without overlapping \n\nUsage:\n(Taken straight from the v0.25.0 Changelog)\nIntroducing Smart Labels! When smart_position is set for LabelAnnotator, RichLabelAnnotator or VertexLabelAnnotator, the labels will move around to avoid overlapping others. (#1625)\n\nAcceptance\nThe PR was accepted before #Hacktoberfest was over, and is now part of the v0.25.0 release of supervision\n","path":null},{"url":"https://kshitijaucharmal.github.io/blog/flappyneat/","title":"Flappy NEAT","description":null,"body":"INC Machine Learning Project\nWelcome to the INC (Impetus and Concepts) Machine Learning Project repository!\nIn this project, we have implemented the NEAT (NeuroEvolution of Augmenting Topologies)\nalgorithm from scratch, using the official research paper as our primary guide.\nOur goal was to explore and demonstrate the power of NEAT in evolving neural networks for tasks like playing games.\nProject Overview\nNEAT Algorithm\nNEAT is a powerful evolutionary algorithm for evolving artificial neural networks.\nIt is especially well-suited for problems where the network’s architecture itself needs to evolve,\nmaking it a valuable tool in reinforcement learning tasks, like game playing.\nOur implementation closely follows the principles outlined in the original NEAT paper:\n\nOriginal NEAT Paper\n\nFlappy Bird Clone\nTo test the capabilities of our NEAT implementation,\nwe created a Flappy Bird clone using the Pygame library.\nFlappy Bird is a simple yet challenging game where a bird must navigate through pipes by jumping.\nOur goal was to evolve neural networks capable of playing the game and achieving high scores autonomously.\nRepository Structure\n\nneat: Folder containing implementation of the NEAT algorithm.\ngame: The Flappy Bird game folder (All Game specific files).\n__main__.py: The main script to run NEAT on the Flappy Bird game.\nREADME.md: You’re reading it right now!\n\nGetting Started\nTo get started with this project, follow these steps:\n\n\nClone this repository to your local machine:\n\n\n\nInstall the necessary dependencies. You can use pip to install them:\n\n\n\nRun the NEAT algorithm on the Flappy Bird game:\n\nThis will start the training process and display the progress of the evolving neural networks as they learn to play the game.\n\n\nConfiguration\n\n!!! Not implemented yet !!!\n\nYou can fine-tune the NEAT algorithm by modifying the parameters in the config.txt file.\nThese parameters include population size, mutation rates, and various other settings that can influence the evolution process.\nContributors\n\nKshitij Aucharmal - Algorithm Implementation\nAlisha Shaikh - Game Development\nTanish Chaudhari - Project Management\n\nContributing\nContributions are always welcome!!\nJust fork the repository and create a pull request with your desired changes, we’ll be sure to review them as soon as possible!\nAcknowledgments\nWe would like to express our gratitude to the creators of the NEAT algorithm for their pioneering work in neuroevolution.\nThis project wouldn’t have been possible without their research.\nLicense\nThis project is licensed under the GPL 3.0 License - see the LICENSE file for details.\n\nFeel free to explore the code, experiment with the NEAT parameters,\nand enjoy watching neural networks learn to play Flappy Bird!\nIf you have any questions or suggestions,\nplease don’t hesitate to open an issue\nor reach out to us.\nHappy coding!\n","path":null},{"url":"https://kshitijaucharmal.github.io/blog/bishopchallenge/","title":"Bishop Challenge","description":null,"body":"Unleash Your Chess Genius: The Bishop Exchange Puzzle Game!\nIntroduction\nDive into the thrilling world of chess challenges with a game that\nI crafted in Unity!\nI recently stumbled upon a unique puzzle that couldn’t be found anywhere else on the internet.\nSo, naturally, I turned it into a game that’s bound to electrify your strategic senses.\nWelcome to the Bishop Challenge,\nwhere the objective is to swap the positions of the\nwhite and black bishops on a compact chess board filled with surprises!\nRules\n\nObjective: Brace yourself for the ultimate chess challenge – exchange the positions of the white and black bishops on a tightly packed 5x4 chess board.\nBoard Size: The game unfolds on this compact battlefield, where the 5x4 board limits the movement of your chess pieces, adding an extra layer of excitement to the puzzle.\nPiece Placement: Every piece stands proudly on squares of the same color, setting the stage for a visually striking and uniquely challenging experience.\nNon-Interference: Here’s the twist – no bishop of a different color can dare to step into the attack range of another! It’s not just chess; it’s a strategic showdown.\n\nHow to Conquer the Challenge\nGet ready for a rollercoaster of moves as you kick off the puzzle on the 5x4 chess board.\nEach move is a carefully calculated step toward achieving the mind-bending objective\nof swapping those bishops. With limited space and an unyielding rule against interference,\nevery move becomes a pulse-pounding decision that could make or break your victory.\nStrategize Like a Pro\nTo conquer this chess puzzle, you’ll need to channel your inner chess genius.\nStrategize, plan, and execute your moves with precision.\nFactor in the restricted board space, anticipate potential blockades,\nand above all, abide by the non-interference rule.\nYour journey through this puzzle is a strategic dance, and every move\npropels you closer to the grand prize – the thrilling exchange of bishops.\nConclusion\nEmbark on a chess adventure like no other with the 5x4 Bishop Exchange Puzzle Game!\nCrafted with passion and excitement, this puzzle promises an adrenaline-pumping experience\nthat will test your chess prowess. Can you crack the code and make those bishops dance?\nGet ready for the challenge of a lifetime – it’s time to unleash your inner chess genius!\n","path":null},{"url":"https://kshitijaucharmal.github.io/games/","title":"Games","description":null,"body":"\n\t\n\n\n","path":null},{"url":"https://kshitijaucharmal.github.io/games/cursedcollectibles/","title":"Cursed Collectibles","description":null,"body":"\nDescription\n","path":null},{"url":"https://kshitijaucharmal.github.io/games/mazemaster/","title":"Maze Master 2","description":null,"body":"\nDescription\n","path":null},{"url":"https://kshitijaucharmal.github.io/games/oceano/","title":"Oceano","description":null,"body":"\nDescription\n","path":null},{"url":"https://kshitijaucharmal.github.io/games/orbitoutbreak/","title":"Orbit Outbreak","description":null,"body":"\nDescription\n","path":null},{"url":"https://kshitijaucharmal.github.io/games/rewind/","title":"REWIND","description":null,"body":"\nDescription\n","path":null},{"url":"https://kshitijaucharmal.github.io/games/stickytanks/","title":"Sticky Tanks","description":null,"body":"\nDescription\n","path":null},{"url":"https://kshitijaucharmal.github.io/games/swampmaster/","title":"Swamp Master","description":null,"body":"\nDescription\n","path":null},{"url":"https://kshitijaucharmal.github.io/games/bishopchallenge/","title":"Bishop Challenge","description":null,"body":"\nClick Here to Play Now!\nDescription\nThis is a challenge that I was reminded of recently, and I didn’t find the exact one anywhere on the internet,\nso I though I would make this a game to challenge everyone to solve this short but hard puzzle.\nThe rules have not been implemented in the game yet so here they are:\nRules:\n\nThe objective of the puzzle is to exchange the white and the black bishops’ positions.\nThe chess board is a 5x4 board which restricts the movement\nAll the pieces are on the same color.\nNo Bishop of different color can come in the attack range of another (programmed in the game).\n\nThat’s it!!\nIf you solve it, make sure to send me a screenshot/moves you did to solve the puzzle on my email\nTHANK YOU!\n","path":null},{"url":"https://kshitijaucharmal.github.io/projects/","title":"Projects","description":null,"body":"\n\t\n\n\n","path":null},{"url":"https://kshitijaucharmal.github.io/projects/neat-q-city/","title":"Neat-Q-City","description":null,"body":"NEAT Q City\nEvolving Deep Q-Learning for Sustainable Virtual City Management (INC @ PICT College)\nThis project investigates the synergy between Deep Q-learning (DQL)\nand Neuro-Evolution of Augmenting Topologies (NEAT) for managing a dynamic,\nvirtual city simulation within the context of the INC competition at PICT College.\nThe goal is to develop an AI agent that learns optimal decisions to enhance the city’s well-being,\nbalancing factors like air quality, resource management, and economic growth.\n\nApproach\n\nSimulated City Environment: We create a simulated virtual city environment that captures essential aspects like air quality index, resource levels, and economic indicators. The environment provides state information (e.g., current air quality) and responds to the agent’s actions (e.g., building infrastructure).\nDeep Q-Learning Agent: A DQL agent interacts with the simulated city. It receives state information from the environment, employs a deep neural network to predict future rewards for different actions, and takes the action with the highest predicted reward. The agent’s performance is evaluated based on a reward function that incentivizes sustainable and beneficial actions for the city.\nNEAT for Evolving Network Topologies: NEAT manages a population of diverse DQL agents with varying network configurations. Through mutation operators (adding/removing connections or nodes) and crossover (combining genetic material), NEAT fosters the evolution of potentially more effective agents across generations. In each generation, agents are evaluated based on their performance within the simulated city, and the best-performing agents are selected for reproduction with variations introduced through mutations.\n\n\nExecution\n\nSet Up Simulation and Parameters: Configure the simulation environment, DQL parameters (network architecture, learning rate), and NEAT parameters (population size, mutation rate).\nRun NEAT Evolution: NEAT iterates through generations, evaluating the performance of each agent in the simulated city and selecting the best ones for reproduction with mutations, leading to a population with potentially improved decision-making strategies.\nEvaluation and Visualization (Optional): Track and visualize the performance of agents across generations, analyzing how the evolved agents’ actions impact the virtual city’s sustainability metrics.\n\nThis project explores the potential of combining DQL and NEAT for evolving effective AI agents to manage complex urban environments in a simulated setting. By participating in the INC competition, we aim to showcase this approach and contribute to advancements in AI-powered urban planning and policy optimization.\n","path":null},{"url":"https://kshitijaucharmal.github.io/","title":"Home","description":null,"body":"\n\t\n\n\n\nWelcome to My Personal Website!\nHello, and thank you for visiting my corner of the web!\nI’m passionate about technology and problem-solving,\nalways eager to tackle new challenges and learn along the way !!\n(Yeah, generated the above text from an LLM.)\n\nHow this website is divided\nI’m not a web developer by any stretch of the imagination (I really don’t wanna be either), but\nwriting blogs will help me share my progress with others, and also keep a log of what i do.\nSo this website is not exactly cleanl structured, I tried to make it this way, but might not be this way always:\n\nBlog: I try to write daily blog showcasing my progress, so this will be the latest section\nProjects: Mostly the projects I’ve undertaken might be here, many I forget to write about so they stay on my laptop\nGames: I’m also a game developer, checkout my games (mostly game jam games) on this page\nAbout: Stuff about my preferences, what softwares I use / recommend etc.\nInspiration: The youtube channels I watch and love, really recommended check them out!!\n\nThis website is creating using the duckquill theme from zola (a static website generator). Scroll down for links to both of these\n\nWhat You’ll Find Here\nIn this website, you’ll find my projects, tutorials, and write-ups / blogs on topics I’m passionate about, or am working on.\nWhether you’re here to learn, collaborate, or just explore, I hope you’ll find something that piques your interest.\nI’m currently working on a simulation engine which is AI enabled (thats a mouthful), and plan to make this into a startup,\nso do check out the progress on my blog!!\n","path":null},{"url":"https://kshitijaucharmal.github.io/inspiration/","title":"My Inspirations","description":null,"body":"\n\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","path":null},{"url":"https://kshitijaucharmal.github.io/about/","title":"About","description":null,"body":"\n\t\n\n\nWhat this website is about\nThis website is about the things I do as a programmer, gamedevloper, and AI Developer (All Unofficially)\nI have done a lot of projects, and am trying for GSoC’25 next year.\n\nMy youtube channel\n\nYoutube Link\n\n\n\n\nMy Configs\n\nNeoSpark My Neovim Config\nQtile My Qtile Config\nAll dots All dot files managed by stow.\n\nOnline Projects\n\nGrid World: A simple test of basic Q learning on a grid world\nNEAT Algorithm Visualization: NeuroEvolution Of Augumenting Topologies Algorithm Implemented in Javascript (p5.js)\nBishop Challenge: A Game/Challenge I Made On a puzzle I know from somewhere, but cant find anywhere on the internet\nDots: A simple genetic Algorithm which learns to reach a target over generations (no neural net involved)\n\nPassion Projects (On Github / Gitlab):\n\nMaze-Generator: A Simple Recursive Backtracking Algorithm to generate mazes\nGrid World: Soruce code for the above mentioned gridworld website\nGrid World In Processing: Source Code for the Gridworld project in Processing (Works Much better)\nNEAT JS Algorithm: Source Code for the above mentioned NEAT Algorithm in Javascript\nNEAT Algorithm: The Neat Algorithm in Java\nBishop Challenge: Source Code for the above mentioned Bishop Game\nReverse Shell: A simple reverse shell script in python I made with my friend\n\nSmall Algorithms/Projects\n\nGenetic Sentences: First try at a genetic Algorithm (Evolves a target word)\nKMeans Clustering: Classic K Means Clustering Algorithm Visualized\nLorenz Equation: The Classic Lorenz Equation Visualized\nFlocking Boids: Boids Algorithm\nFlocking Boids 2: Another Boids Algorithm ???\n2048: The classic 2048 Game Written in C++ Raylib\nWaveFunctionCollapse: The wave function collapse Algorithm as understood by me (Its not perfect)\n\n","path":null}]